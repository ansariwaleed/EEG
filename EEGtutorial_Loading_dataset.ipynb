{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwtoDUFI/b+CUZI/6lMDpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansariwaleed/EEG/blob/main/EEGtutorial_Loading_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "In this tutorial, we use the data from EEG Motor Movement/Imagery Dataset (EEG-MMIDB). cleaned dataset which contains 109 subjects.\n",
        "- here we take the first subject as a subject to understand how things works."
      ],
      "metadata": {
        "id": "d8Id4rkTUYkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset description\n",
        "\n",
        "Orignal dataset can be found here: https://archive.physionet.org/pn4/eegmmidb/\n",
        "\n",
        "\n",
        "\n",
        "> After our clearning and sorting, each .npy file comprised of the data of one subject. The data shape of each npy file is [N, 65], the first 64 columns represent the readouts of 64 EEG channel, the last column denotes the class/intent label. The row denotes time-points in signal collection and one row represents one readout at a specific time-point. In this tutorial, we call each row a instance. The sampling rate in EEG-MMIDB is 160 Hz, which means that the equipment can generate 160 instances/rows/time-points in each second.\n",
        "The N varis for different subjects, but N should be 259,520 or 255,680. This is the inherent difference in the original dataset. Recall that the sampling rate is 160 Hz, thus, some trials last for 4.1 seconds while others last for 4.2 seconds: 4.1 seconds (656=4.1\n",
        " 160 instances) or 4.2 seconds (672 = 4.2\n",
        " 160 instancs). It is suggested to segment the signals in each second.\n",
        "\n",
        "Based on the experimental setting, we split all EEG signals into 11 different cognitive intentions as follows. In which, the intentions with image represents the subject only image the action but not move in reality: these four intentions (labelled by 4, 5, 8, and 9) are strictly movement imagery EEG. The residual intentions are rather the mental states that the user was conducting a specific action.\n",
        "\n",
        ">Labels:\n",
        "0: open eyes,\n",
        "1: close eyes.\n",
        "2: left hand,\n",
        "3: right hand.\n",
        "4: image left hand,\n",
        "5: image right hand.\n",
        "6: open fists,\n",
        "7:open feet.\n",
        "8: image fist,\n",
        "9: image feet.\n",
        "10: rest.\n"
      ],
      "metadata": {
        "id": "7RZfyV9YVg1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-XK-XPyXLEx",
        "outputId": "0494900e-1c02-4856-815c-6a56a103c4e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1YM3Fx5TxyK",
        "outputId": "c574d0ae-a21e-45b2-b910-3faf75988743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of Dataset_1: (259520, 65)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-16, -29,   2, ..., -11,  15,   0],\n",
              "       [-56, -54, -27, ...,   1,  21,   0],\n",
              "       [-55, -55, -29, ...,  18,  35,   0],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "#load dataset\n",
        "import numpy as np\n",
        "dataset_1 = np.load('/content/drive/MyDrive/1/1.npy')\n",
        "print('The shape of Dataset_1:', dataset_1.shape)\n",
        "dataset_1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data details\n",
        ">For subject 1, the data consists of:\n",
        "- 259,520 instances (snapshots) collected over time.\n",
        "- 64 channels (sensors) capturing brain activity.\n",
        "- The last column shows the class label (what the person was doing or thinking).\n",
        "\n",
        "##Key Terms\n",
        ">Instance (Time Step/Time Point):\n",
        "- An instance is a snapshot taken at a single moment.\n",
        "- With a 160 Hz sampling rate, 160 instances are collected every second.\n",
        "- We use \"instance\" and \"time point\" to mean the same thing.\n",
        "\n",
        ">Segment (Sample):\n",
        "- A segment is a group of continuous instances representing a specific event or state of brain activity.\n",
        "- The length of a segment is called the time window.\n",
        "- We use \"segment\" and \"sample\" to mean the same thing."
      ],
      "metadata": {
        "id": "feNuXKliKb_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io, os,sys,types\n",
        "from IPython import get_ipython\n",
        "from nbformat import read\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "class NotebookFinder(object):\n",
        "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
        "    def __init__(self):\n",
        "        self.loaders = {}\n",
        "\n",
        "    def find_module(self, fullname, path=None):\n",
        "        nb_path = find_notebook(fullname, path)\n",
        "        if not nb_path:\n",
        "            return\n",
        "\n",
        "        key = path\n",
        "        if path:\n",
        "            # lists aren't hashable\n",
        "            key = os.path.sep.join(path)\n",
        "\n",
        "        if key not in self.loaders:\n",
        "            self.loaders[key] = NotebookLoader(path)\n",
        "        return self.loaders[key]\n",
        "\n",
        "def find_notebook(fullname, path=None):\n",
        "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
        "\n",
        "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
        "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
        "    does not exist.\n",
        "    \"\"\"\n",
        "    name = fullname.rsplit('.', 1)[-1]\n",
        "    if not path:\n",
        "        path = ['']\n",
        "    for d in path:\n",
        "        nb_path = os.path.join(d, name + \".ipynb\")\n",
        "        if os.path.isfile(nb_path):\n",
        "            return nb_path\n",
        "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
        "        nb_path = nb_path.replace(\"_\", \" \")\n",
        "        if os.path.isfile(nb_path):\n",
        "            return nb_path\n",
        "\n",
        "class NotebookLoader(object):\n",
        "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
        "    def __init__(self, path=None):\n",
        "        self.shell = InteractiveShell.instance()\n",
        "        self.path = path\n",
        "\n",
        "    def load_module(self, fullname):\n",
        "        \"\"\"import a notebook as a module\"\"\"\n",
        "        path = find_notebook(fullname, self.path)\n",
        "\n",
        "        print (\"importing Jupyter notebook from %s\" % path)\n",
        "\n",
        "        # load the notebook object\n",
        "        with io.open(path, 'r', encoding='utf-8') as f:\n",
        "            nb = read(f, 4)\n",
        "\n",
        "\n",
        "        # create the module and add it to sys.modules\n",
        "        # if name in sys.modules:\n",
        "        #    return sys.modules[name]\n",
        "        mod = types.ModuleType(fullname)\n",
        "        mod.__file__ = path\n",
        "        mod.__loader__ = self\n",
        "        mod.__dict__['get_ipython'] = get_ipython\n",
        "        sys.modules[fullname] = mod\n",
        "\n",
        "        # extra work to ensure that magics that would affect the user_ns\n",
        "        # actually affect the notebook module's ns\n",
        "        save_user_ns = self.shell.user_ns\n",
        "        self.shell.user_ns = mod.__dict__\n",
        "\n",
        "        try:\n",
        "          for cell in nb.cells:\n",
        "            if cell.cell_type == 'code':\n",
        "                # transform the input to executable Python\n",
        "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
        "                # run the code in themodule\n",
        "                exec(code, mod.__dict__)\n",
        "        finally:\n",
        "            self.shell.user_ns = save_user_ns\n",
        "        return mod\n",
        "sys.meta_path.append(NotebookFinder())"
      ],
      "metadata": {
        "id": "4pMAODegONVS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import butter, lfilter\n",
        "import scipy\n",
        "import numpy as np\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = scipy.signal.lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def one_hot(y_):\n",
        "    y_ = y_.reshape(len(y_))\n",
        "    y_ = [int(xx) for xx in y_]\n",
        "    n_values = np.max(y_) + 1\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
        "import numpy as np\n",
        "def extract(input, n_classes, n_fea, time_window, moving):\n",
        "    xx = input[:, :n_fea]\n",
        "    yy = input[:, n_fea:n_fea + 1]\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    number = int((xx.shape[0] / moving) - 1)\n",
        "    for i in range(number):\n",
        "        ave_y = np.average(yy[int(i * moving):int(i * moving + time_window)])\n",
        "        if ave_y in range(n_classes + 1):\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(ave_y)\n",
        "        else:\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(0)\n",
        "\n",
        "    new_x = np.array(new_x)\n",
        "    new_x = new_x.reshape([-1, n_fea * time_window])\n",
        "    new_y = np.array(new_y)\n",
        "    new_y.shape = [new_y.shape[0], 1]\n",
        "    data = np.hstack((new_x, new_y))\n",
        "    data = np.vstack((data, data[-1]))  # add the last sample again, to make the sample number round\n",
        "    return data"
      ],
      "metadata": {
        "id": "E1amUTP3Ot4y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n_fea = 64  # 64 channels\n",
        "label = dataset_1[:, n_fea: n_fea+1]  # seperate label from feature\n",
        "feature = dataset_1[:, 0:n_fea]\n",
        "feature_f=[]  # feature after filtering\n",
        "\n",
        "# EEG Delta pattern decomposition\n",
        "for i in range(feature.shape[1]):\n",
        "    x = feature[:, i]\n",
        "    fs = 160.0\n",
        "    lowcut = 0.5\n",
        "    highcut = 4.0\n",
        "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=3)\n",
        "    feature_f.append(y)\n",
        "\n",
        "feature_f=np.array(feature_f).T\n",
        "print('The shape of filtered feature:',feature_f.shape)\n",
        "\n",
        "data_f=np.hstack((feature_f,label))  # stack label to filtered feature\n",
        "print(\"The shape of dataset_1 after filtering:\",data_f.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fp_fh2kNhgZ",
        "outputId": "13a55286-f9fa-4130-8543-8e1ca925e22a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of filtered feature: (259520, 64)\n",
            "The shape of dataset_1 after filtering: (259520, 65)\n"
          ]
        }
      ]
    }
  ]
}